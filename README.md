NLP кейс — LLM классификация отзывов
 
Цель: научить LLM-модель классифицировать отзывы с маркетплейсов по категориям товаров, к которым они относятся.

Решение:

Требования:
 - решение рассчитано на выполнение в Google Colab (16GB VRAM T4).
 - В директорию /content пользователь должен положить файлы train.csv и test.csv.
 - В решении используется open-source модели с Hugging-Face, что может потребовать авторизации: внесите HF_TOKEN в среду окружения google colab или выполните авторизацию прямо в коде: 
!pip install huggingface_hub

from huggingface_hub import login
my_token = "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" # для теста можете использовать мой токен - через неделю обновлю
login(my_token)

Ключевые этапы решения задачи

1. Подготовка данных:
 - Исходные данные содержат отзывы с маркетплейсов без категорий -> для формирования обучающей выборки была реализована автоматическая разметка ансамблем моделей. Этапы разметки:
    1. Подготовка текстов: из выборки удаляются пустые и некорректные строки, после чего тексты группируются в батчи фиксированного размера (по 32 примера).
    2. Прогон через ансамбль моделей (функция classify_ensemble_batches):
        Для каждого батча отзывов выполняется классификация двумя независимыми моделями (clf1, clf2).
        Обе модели возвращают список категорий и вероятности принадлежности текста к каждой категории.
        Правило голосования:
            если предсказания совпадали → выбиралась общая категория,
            если различались → выбиралась категория модели с более высоким confidence score.
    3. Формирование итогового датасета:
        Для всех текстов формируются метки label.
        Результаты сохраняются в файл train_labeled.csv

2. Работа с дисбалансом классов:
 - для балансировки категорий использовалась функция augment_text, которая случайным образом выбирает одну из стратегий аугментации:
    1. Синонимическая замена (synonym_replacement): случайное слово заменяется на синоним (через перевод в WordNet и обратно).
    2. Случайное удаление (random_deletion): часть слов из отзыва удаляется с вероятностью p.
    3. Случайная перестановка (random_swap): два случайных слова меняются местами.
    4. Обратный перевод (back_translate): текст переводится на английский и обратно на русский -> получаю естественные переформулировки.
 - для "недопредставленных" классов создавались новые синтетические примеры на основе исходных отзывов.

Такой подход позволил выровнять количество примеров между категориями и повысить устойчивость модели, что положительно сказалось на метрике Weighted F1. Модель для перевода deep_translator выбрана не случайно, а в результате экспериментов (сравнивал с моделью Helsinki-NLP/opus-mt-en-ru / -ru-en).


3. Обучение модели:
 - реализовано в Google Colab с учётом лимитов вычислительных ресурсов (T4 GPU, 16GB VRAM): в основе лежит модель "distilbert-base-multilingual-cased" - оптимальная с точки зрения соотношения ресурсы/точность
 - Полный fine-tuning выбран как основной вариант.
 - Дополнительно тестировались более ресурсоёмкие модели с дообучением адаптеров и quantization (QLoRA), однако выигрыш оказался минимальным при существенном росте потребления GPU и времени обучения, даже при использовании 1.1 % обучаемых параметров.
 
 - обучение и инференс выполнялись в рамках доступных ресурсов Google Colab: среднее потребление GPU составило 6464MiB / 15360MiB.
Также выбор не случайнен - сравнивал с QLoRA дообучением vicgalle/xlm-roberta-large-xnli-anli:
MODEL_NAME = "vicgalle/xlm-roberta-large-xnli-anli"
bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_use_double_quant=True,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_compute_dtype=torch.bfloat16
)

tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
if tokenizer.pad_token is None:
    tokenizer.pad_token = tokenizer.eos_token if tokenizer.eos_token else tokenizer.unk_token

model = AutoModelForSequenceClassification.from_pretrained(
    MODEL_NAME,
    num_labels=9,
    quantization_config=bnb_config,
    device_map={"": 0}
)

Показатель weighted-F1 приблизительно 0.9 при значительном увеличении потребления GPU и времени fine-tunning.

4. Оценка качества и инференс:
 - для оценки использовалась метрика Weighted F1 по всем категориям, включая «нет товара».
 - тестовый набор не использовался для обучения или валидации и оставался «слепым» до финальной оценки.- среднее время классификации одного отзыва меньше 5 секунд, что соответствует ограничению из условий кейса.

5. Итоговый результат:
 - разработан полный пайплайн: от автоматической разметки данных и балансировки классов до обучения модели и генерации предсказаний.
 - структура:
    1. Jupyter Notebook с кодом (NLP_case_Tbank.ipynb),
    2. CSV с предсказанными категориями для тестового набора,
    3. README с описанием этапов решения.
