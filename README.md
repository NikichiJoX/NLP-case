NLP кейс — LLM классификация отзывов
 
Цель: научить LLM-модель классифицировать отзывы с маркетплейсов по категориям товаров, к которым они относятся.

Решение:

Требования:
 - решение рассчитано на выполнение в Google Colab (16GB VRAM T4).
 - В директорию /content пользователь должен положить файлы train.csv и test.csv.

Ключевые этапы решения задачи

1. Подготовка данных:
 - Исходные данные содержат отзывы с маркетплейсов без категорий -> для формирования обучающей выборки была реализована автоматическая разметка ансамблем моделей. Этапы разметки:
    1. Подготовка текстов: из выборки удаляются пустые и некорректные строки, после чего тексты группируются в батчи фиксированного размера (по 32 примера).
    2. Прогон через ансамбль моделей (функция classify_ensemble_batches):
        Для каждого батча отзывов выполняется классификация двумя независимыми моделями (clf1, clf2).
        Обе модели возвращают список категорий и вероятности принадлежности текста к каждой категории.
        Правило голосования:
            если предсказания совпадали → выбиралась общая категория,
            если различались → выбиралась категория модели с более высоким confidence score.
    3. Формирование итогового датасета:
        Для всех текстов формируются метки label.
        Результаты сохраняются в файл train_labeled.csv

2. Работа с дисбалансом классов:
 - для балансировки категорий использовалась функция augment_text, которая случайным образом выбирает одну из стратегий аугментации:
    1. Синонимическая замена (synonym_replacement): случайное слово заменяется на синоним (через перевод в WordNet и обратно).
    2. Случайное удаление (random_deletion): часть слов из отзыва удаляется с вероятностью p.
    3. Случайная перестановка (random_swap): два случайных слова меняются местами.
    4. Обратный перевод (back_translate): текст переводится на английский и обратно на русский -> получаю естественные переформулировки.
 - для "недопредставленных" классов создавались новые синтетические примеры на основе исходных отзывов.

Такой подход позволил выровнять количество примеров между категориями и повысить устойчивость модели, что положительно сказалось на метрике Weighted F1.


3. Обучение модели:
 - реализовано в Google Colab с учётом лимитов вычислительных ресурсов (T4 GPU, 16GB VRAM): в основе лежит модель "distilbert-base-multilingual-cased" - оптимальная с точки зрения соотношения ресурсы/точность
 - Полный fine-tuning выбран как основной вариант.
 - Дополнительно тестировались более ресурсоёмкие модели с дообучением адаптеров и quantization (QLoRA), однако выигрыш оказался минимальным при существенном росте потребления GPU и времени обучения, даже при использовании 1.1 % обучаемых параметров.
 
 - обучение и инференс выполнялись в рамках доступных ресурсов Google Colab: среднее потребление GPU составило 6464MiB / 15360MiB.

4. Оценка качества и инференс:
 - для оценки использовалась метрика Weighted F1 по всем категориям, включая «нет товара».
 - тестовый набор не использовался для обучения или валидации и оставался «слепым» до финальной оценки.- среднее время классификации одного отзыва меньше 5 секунд, что соответствует ограничению из условий кейса.

5. Итоговый результат:
 - разработан полный пайплайн: от автоматической разметки данных и балансировки классов до обучения модели и генерации предсказаний.
 - структура:
    1. Jupyter Notebook с кодом (NLP_case_T_bank.ipynb),
    2. CSV с предсказанными категориями для тестового набора,
    3. README с описанием этапов решения.
